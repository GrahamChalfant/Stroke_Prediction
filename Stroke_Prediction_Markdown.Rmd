---
title: "Stroke_Prediction_RMD"
author: "Graham Chalfant"
date: "8/18/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#https://rpubs.com/bharath2925/strokeprediction
```

```{r, echo=FALSE}
library(tidyverse)
library(caTools) #Data partitioning 
library(e1071)
library(caret)
library(ROSE)
library(randomForest)
library(DMwR)
```

## Data Preparation
```{r}
data <- read_csv("healthcare-dataset-stroke-data.csv")

#View(data)

summary(data)# 201 NA's in BMI 

#Remove id - does not add to the analysis 
data$id <- NULL

#Remove N/A values from BMI - na.omit() was not working 
data <- data %>% filter(bmi != "N/A") 


str(data)#Need to change data type for some variables 

#Change hypertension and heart_disease to factor 
data$gender <- as.factor(data$gender)
data$hypertension<- factor(data$hypertension, levels = c(0,1), labels = c("No", "Yes"))
data$heart_disease<- factor(data$heart_disease, levels = c(0,1), labels = c("No", "Yes"))
data$ever_married <- as.factor(data$ever_married)
data$work_type <- as.factor(data$work_type)
data$Residence_type <- as.factor(data$Residence_type)
data$bmi<-as.numeric(data$bmi)
data$smoking_status <- as.factor(data$smoking_status)
data$stroke<- factor(data$stroke, levels = c(0,1), labels = c("No", "Yes"))

summary(data)

table(data$gender)#only one 'other' gender 

data <- data %>% filter(gender != 'Other')#Removed single observation 
```


## Data Exploration 
```{r}
ggplot(data, aes(x = age, y = bmi, color = stroke)) + geom_point() + labs(title = "Stoke by Age and Average Glucose Level", x = "Age", y = "BMI", color = "Stroke") 
```

```{r}
ggplot(data, aes(x = age, fill = stroke)) + geom_histogram() + facet_wrap(data$gender) + labs(title = "Stroke by Age and Gender", x = "Age", y = "Frequency")

```

```{r}
ggplot(data, aes(x = age, fill = stroke)) + geom_histogram() + facet_wrap(data$work_type) + labs(title = "Stroke by Age and Work Type", x = "Age", y = "Frequency")
```


```{r}
boxplot.stats(data$avg_glucose_level)
boxplot(data$avg_glucose_level)
data <- data %>% filter(avg_glucose_level <= 170)

boxplot.stats(data$bmi)
boxplot(data$bmi)
data <- data %>% filter(bmi <= 50)
```



## Partitioning Data
```{r}
#Set seed
set.seed(10)

# Generate a vector partition for data partitioning 
partition <- sample.split(data$stroke, SplitRatio = .70) 

training <- subset(data, partition == "TRUE")

test <- subset(data, partition == "FALSE")

table(training$stroke)#Data is highly imbalanced 

```





### RF tuned

```{r}

# subset function will take a subset from our training data by excluding CLASS column (or target variable)
trainingFeatures = subset(training, select = -stroke )

# Set the seed for reproducibility
set.seed(111)
tuneRF(trainingFeatures, training$stroke, mtryStart = 3, ntree = 800, stepFactor = 1.5, improve = 0.01)

#mtry = 3 has the samllest error rate

```

```{r  message=FALSE, eval = FALSE}


# Build Random Forest model and assign it to RF_model
RF_model <- randomForest(stroke~., training, mtry = 3, ntree = 800)

# Predict the class of the test data
prediction_RF <- predict(RF_model, test)

# Confusion matrix
confusionMatrix(predict(model_RF, test), test$stroke)

```



### RF overfitting check 
```{r}
prediction_RF_fit <- predict(RF_model, training)

# Confusion matrix
confusionMatrix(predict(RF_model, training), training$stroke) #Overfit but not as bad as oversampled data

```


### RF tuned with oversampled data

```{r}

# subset function will take a subset from our training data by excluding CLASS column (or target variable)
trainingFeaturesOver = subset(over.training, select = -stroke )

# Set the seed for reproducibility
set.seed(111)
tuneRF(trainingFeaturesOver, over.training$stroke, mtryStart = 3, ntree = 800, stepFactor = 1.5, improve = 0.01)

#mtry = 4 has the smallest error rate

```

```{r  message=FALSE, eval = FALSE}


# Build Random Forest model and assign it to RF_model
RF_model_over <- randomForest(stroke~., over.training, mtry = 4, ntree = 800)

# Predict the class of the test data
prediction_RF_over <- predict(RF_model_over, test)

# Confusion matrix
confusionMatrix(predict(RF_model_over, test), test$stroke)

```


### RF overfitting check 
```{r}
prediction_RF_over_fit <- predict(RF_model_over, over.training)

# Confusion matrix
confusionMatrix(predict(RF_model_over, over.training), over.training$stroke) #very overfit 

```


#Plotting results

```{r  message=FALSE, eval = FALSE}
library(pROC)

# Obtain class probabilities by using predict() and adding type = "prob" for Random Forest
RF_prob <- predict(RF_model, test, type = "prob")  #the second column belongs to churn


ROC_RF <- roc(test$stroke, RF_prob[ ,2])

# Extract required data from ROC_RF
df_RF = data.frame((1-ROC_RF$specificities), ROC_RF$sensitivities)

```

```{r  message=FALSE, eval = FALSE}

#plot the ROC curve for random forst

plot(ROC_RF, col="red", type="l", 
xlab="False Positive Rate (1-Specificity)", ylab="True Positive Rate (Sensitivity)")          #adds ROC curve for SVM
lines(ROC_RF, col="green")              


abline(a = 0, b = 1, col = "lightgray") #adds a diagonal line


```

